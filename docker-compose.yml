version: '2'

services:

  ganglia:
    container_name: ganglia
    image: wookietreiber/ganglia
    hostname: ganglia
    domainname: hadoop
    ports:
      - "127.0.0.1:80:8080"

  namenode:
    image: uhopper/hadoop-namenode
    container_name: namenode
    hostname: namenode
    networks:
      - hadoop
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      CLUSTER_NAME: uh-cluster
      constraint:node=: onet1
    env_file:
      - ./hadoop.env
    ports:
      - "50070:50070"
      - "8020:8020"

  resourcemanager:
    image: uhopper/hadoop-resourcemanager
    container_name: resourcemanager
    hostname: resourcemanager
    depends_on:
      - namenode
    networks:
      - hadoop
    environment:
      constraint:node=: onet1
    env_file:
      - ./hadoop.env
    ports:
      - "8088:8088"
      - "8030:8030"
      - "8031:8031"
      - "8032:8032"
      - "8033:8033"

  historyserver:
    image: uhopper/hadoop-historyserver
    container_name: historyserver
    hostname: historyserver
    depends_on:
      - namenode
    networks:
      - hadoop
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    environment:
      constraint:node=: onet1
    env_file:
      - ./hadoop.env
    ports:
      - "8188:8188"
      - "10200:10200"

  spark:
    image: uhopper/hadoop-spark
    container_name: spark
    hostname: spark
    networks:
      - hadoop
    environment:
      constraint:node=: onet1
    env_file:
      - ./hadoop.env
    ports:
      - "18080:18080"
    command: historyserver

  nodemanager1:
    image: uhopper/hadoop-nodemanager
    container_name: nodemanager1
    hostname: nodemanager1
    depends_on:
      - namenode
      - resourcemanager
    networks:
      - hadoop
      - kafka
    environment:
      constraint:node=: onet1
    env_file:
      - ./hadoop.env

  nodemanager2:
    image: uhopper/hadoop-nodemanager
    container_name: nodemanager2
    hostname: nodemanager2
    depends_on:
      - namenode
      - resourcemanager
    networks:
      - hadoop
      - kafka
    environment:
      constraint:node=: onet2
    env_file:
      - ./hadoop.env

  datanode1:
    image: uhopper/hadoop-datanode
    container_name: datanode1
    hostname: datanode1
    depends_on:
      - namenode
    networks:
      - hadoop
    volumes:
      - hadoop_datanode1:/hadoop/dfs/data
    environment:
      constraint:node=: onet1
    env_file:
      - ./hadoop.env

  datanode2:
    image: uhopper/hadoop-datanode
    container_name: datanode2
    hostname: datanode2
    depends_on:
      - namenode
    networks:
      - hadoop
    volumes:
      - hadoop_datanode2:/hadoop/dfs/data
    environment:
      constraint:node=: onet2
    env_file:
      - ./hadoop.env

networks:
  kafka:
    external: true
  hadoop:
    external: true

volumes:
  hadoop_namenode:
    external: true

  hadoop_datanode1:
    external: true

  hadoop_datanode2:
    external: true

  hadoop_historyserver:
    external: true
