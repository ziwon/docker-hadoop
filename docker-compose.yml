version: '2'

services:

  namenode:
    image: uhopper/hadoop-namenode:2.8.1
    container_name: namenode
    hostname: namenode
    networks:
      - hadoop
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      CLUSTER_NAME: uh-cluster
      constraint:node=: onet1
    env_file:
      - ./hadoop.env
    ports:
      - "50070:50070"
      - "8020:8020"

  resourcemanager:
    image: uhopper/hadoop-resourcemanager:2.8.1
    container_name: resourcemanager
    hostname: resourcemanager
    depends_on:
      - namenode
    networks:
      - hadoop
    environment:
      constraint:node=: onet1
    env_file:
      - ./hadoop.env
    ports:
      - "8088:8088"
      - "8030:8030"
      - "8031:8031"
      - "8032:8032"
      - "8033:8033"

  historyserver:
    image: uhopper/hadoop-historyserver:2.8.1
    container_name: historyserver
    hostname: historyserver
    depends_on:
      - namenode
    networks:
      - hadoop
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    environment:
      constraint:node=: onet1
    env_file:
      - ./hadoop.env
    depends_on:
      - namenode
    ports:
      - "8188:8188"
      - "10200:10200"

  spark:
    image: uhopper/hadoop-spark:2.0.2_2.8.1
    container_name: spark
    hostname: spark
    networks:
      - hadoop
    environment:
      constraint:node=: onet1
    env_file:
      - ./hadoop.env
    ports:
      - "18080:18080"
    command: historyserver

  nodemanager1:
    image: uhopper/hadoop-nodemanager:2.8.1
    container_name: nodemanager1
    hostname: nodemanager1
    depends_on:
      - namenode
      - resourcemanager
    networks:
      - hadoop
      - kafka
    environment:
      constraint:node=: onet1
    env_file:
      - ./hadoop.env

  nodemanager2:
    image: uhopper/hadoop-nodemanager:2.8.1
    container_name: nodemanager2
    hostname: nodemanager2
    depends_on:
      - namenode
      - resourcemanager
    networks:
      - hadoop
      - kafka
    environment:
      constraint:node=: onet2
    env_file:
      - ./hadoop.env

  datanode1:
    image: uhopper/hadoop-datanode:2.8.1
    container_name: datanode1
    hostname: datanode1
    depends_on:
      - namenode
    networks:
      - hadoop
    volumes:
      - hadoop_datanode1:/hadoop/dfs/data
    environment:
      constraint:node=: onet1
    env_file:
      - ./hadoop.env

  datanode2:
    image: uhopper/hadoop-datanode:2.8.1
    container_name: datanode2
    hostname: datanode2
    depends_on:
      - namenode
    networks:
      - hadoop
    volumes:
      - hadoop_datanode2:/hadoop/dfs/data
    environment:
      constraint:node=: onet2
    env_file:
      - ./hadoop.env

  spark-master:
    image: uhopper/hadoop-spark:2.0.2_2.8.1
    container_name: spark-master
    hostname: spark-master
    networks:
      - hadoop
    environment:
      constraint:node=: onet1
    env_file:
      - ./hadoop.env
    ports:
      - "8080:8080"
      - "7077:7077"
      - "6066:6066"
    depends_on:
      - namenode
      - datanode1
      - datanode2
    command: master

  spark-slave1:
    image: uhopper/hadoop-spark:2.0.2_2.8.1
    container_name: spark-slave1
    hostname: spark-slave1
    networks:
      - hadoop
    environment:
      - "constraint:node=: onet1"
    env_file:
      - ./hadoop.env
    depends_on:
      - spark-master
    command: slave spark://spark-master:7077

  spark-slave2:
    image: uhopper/hadoop-spark:2.0.2_2.8.1
    container_name: spark-slave2
    hostname: spark-slave2
    networks:
      - hadoop
    environment:
      - "constraint:node=: onet2"
    env_file:
      - ./hadoop.env
    depends_on:
      - spark-master
    command: slave spark://spark-master:7077

networks:
  kafka:
    external: true
  hadoop:
    external: true

volumes:
  hadoop_namenode:
    external: true

  hadoop_datanode1:
    external: true

  hadoop_datanode2:
    external: true

  hadoop_historyserver:
    external: true
